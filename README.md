# AI Tudor â€“ AI Code Tutor

A **solo-user** AI-powered code tutoring application with voice support, mock API, and interactive playground. Built as a Next.js monorepo with TypeScript.

## ğŸš€ Features

### Core Functionality
- **Chat Interface** (`/`) - Ask questions, get structured AI responses with steps and Socratic questions
- **Playground** (`/learn/playground`) - Write code, run it, or get explanations with AI assistance
- **Mock AI API** - Fully functional without external LLM dependencies
- **Solo User** - No authentication required, everything works locally

### Voice Support (Web APIs)
- **Speech Recognition** - Voice input for both chat and code (Web Speech API)
- **Text-to-Speech** - AI responses read aloud (Speech Synthesis API)
- **Settings** - Language (EN/PL), rate, pitch controls (stored in localStorage)
- **Graceful Fallback** - Works without voice support, shows appropriate UI states

### Technical Stack
- **Framework:** Next.js 14 (App Router) + React 18
- **Language:** TypeScript everywhere
- **Styling:** Tailwind CSS with dark theme
- **State:** Zustand for voice settings persistence
- **Testing:** Vitest + React Testing Library
- **Voice:** Web Speech API + Speech Synthesis API

## ğŸ“ Project Structure
```
apps/web/                   # Main Next.js application
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ (app)/page.tsx     # Chat homepage
â”‚   â”œâ”€â”€ learn/playground/   # Code playground
â”‚   â””â”€â”€ api/
â”‚       â”œâ”€â”€ health/        # Health check endpoint
â”‚       â””â”€â”€ tutor/         # Main AI tutor API
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ lib/tutor/         # API types & validation
â”‚   â”œâ”€â”€ store/             # Zustand stores (voice settings)
â”‚   â”œâ”€â”€ hooks/             # React hooks (useTutorChat)
â”‚   â””â”€â”€ __tests__/         # Test suites
packages/
â”œâ”€â”€ core/                  # Shared logic & Prisma
â”‚   â”œâ”€â”€ src/hooks/         # Speech recognition & synthesis
â”‚   â””â”€â”€ src/utils/         # Prisma client (noop fallback)
â””â”€â”€ ui/                    # Reusable components
    â””â”€â”€ src/components/    # ChatComposer, ChatMessageList
```

## ğŸ›  Getting Started

### Prerequisites
- Node.js 18+
- pnpm 8+

### Installation & Development
```bash
# Install dependencies
pnpm install

# Start development server
pnpm dev

# Open browser
open http://localhost:3000
```

### Environment Setup (Optional)
```bash
cp .env.example .env
# Edit .env with your preferred settings
```

**Note:** App works fully with mock data - no API keys required!

## ğŸ”§ Available Scripts

| Command | Description |
| --- | --- |
| `pnpm dev` | Start development server (http://localhost:3000) |
| `pnpm build` | Build all packages and apps for production |
| `pnpm lint` | Run ESLint across all workspaces |
| `pnpm test` | Run Vitest test suites |
| `pnpm format` | Format code with Prettier |

## ğŸ¤ Voice Features

### Browser Support
- **Chrome/Edge** - Full Web Speech API support
- **Safari** - Speech Synthesis only (no recognition)
- **Firefox** - Limited support
- **Mobile** - Varies by platform

### Voice Controls
- **ğŸ¤ Mic Button** - Start/stop voice input (turns red when recording)
- **ğŸ”Š Speaker Button** - Enable/disable voice output
- **Settings** - Language, rate, and pitch stored in localStorage

### Keyboard Shortcuts
- Chat: Type normally, voice transcription appends to input
- Playground: Voice input adds to code editor

## ğŸ§ª Testing & CI

- **Unit Tests** - API validation, component rendering
- **Integration Tests** - Mock API endpoints, voice API mocking
- **CI Pipeline** - GitHub Actions: lint â†’ test â†’ build

## ğŸš€ Production Deployment

```bash
# Build for production
pnpm build

# Static export (if needed)
pnpm export
```

## ğŸ”® Future Enhancements

### Planned Features
1. **Real LLM Integration** - Replace mocks with OpenAI/Anthropic APIs
2. **Code Execution** - Safe sandboxed code running
3. **User Progress** - Learning path tracking with Prisma
4. **Mobile App** - React Native companion
5. **Advanced Voice** - Whisper integration for better STT

### Architecture Notes
- **Solo-user first** - No complex auth/multi-tenancy
- **Progressive enhancement** - Works without voice, better with it
- **API-ready** - Easy to swap mock with real LLM endpoints

## ğŸ“œ License

MIT - Feel free to use for learning and projects!
